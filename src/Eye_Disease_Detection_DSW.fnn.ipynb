{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessaryy libraries for the Neural Network\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing import image\n",
    "from IPython.display import SVG\n",
    "from IPython.display import Image\n",
    "from keras.utils import plot_model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making an object of sequential class that initializes the CNN\n",
    "eye_NN = Sequential()\n",
    "\n",
    "# Adding a convolutional layer that takes input image of size 150X150\n",
    "# This layer contains 64 filters of kernel size 3 each\n",
    "# Activation function for the neurons or nodes in this layer is 'relu'\n",
    "eye_NN.add(Convolution2D(64, 3, 3, input_shape = (150, 150, 3), activation = 'relu'))\n",
    "\n",
    "# Max Pooling layer to extarct the prominent features from the images which helps in better prediction of the images\n",
    "eye_NN.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# The second convolution layer does exactly what the firs layer does \n",
    "# Adding another layer helps fine tune the model even further\n",
    "# This layer contains 64 filters of kernel size 3 each\n",
    "eye_NN.add(Convolution2D(64, 3, 3, activation = 'relu'))\n",
    "\n",
    "# Also another max pooling layer to extract the more prominent features from the images that passes through the 2nd convolution layer\n",
    "eye_NN.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# This is the third and the last convolutional layer which has 32 filters\n",
    "eye_NN.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
    "\n",
    "#Another max pooling layer helps in increasing the overall accuracy of the model\n",
    "eye_NN.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "# The flatten layer is absolutely essential which flattens the matrix of numbers representing the filtered and pooled images into a single row of numbers\n",
    "\n",
    "eye_NN.add(Flatten())\n",
    "\n",
    "# In this layer we establish the full connection with all the layers of the neural network\n",
    "#This output layer contains 256 nodes which will further help in increasing the accuracy of the model\n",
    "eye_NN.add(Dense(output_dim = 256, activation = 'relu'))\n",
    "\n",
    "#This dense layer outputs the classes which we are trying to represent in the form of a single digit\n",
    "eye_NN.add(Dense(output_dim = 4, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comiling the neural network with 'adam' optimizer\n",
    "eye_NN.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)   \n",
    "# rescale  will rescale the pixel values from 0-255 to 0-1 which makes training faster \n",
    "# shear_range will randomly shear images from different sides\n",
    "# zoom_range will randomly zoom the images\n",
    "# horizontal_filp will randomly flip half of the images horizontally\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "# the reson we dont apply the other three parameteres is beacuse that will dpend upon the user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 451 images belonging to 4 classes.\n",
      "Found 150 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# training_set comtains 450 images from 4 classes of images 1.normal 2.cataract 3.glaucoma 4.Retina Disease\n",
    "# batch_size of 10 specifies the gap after which the model gets updated\n",
    "training_set = train_datagen.flow_from_directory('final_1/train',target_size = (150, 150),batch_size = 10, class_mode = 'categorical')\n",
    "\n",
    "# test_set comtains 150 images from 4 classes of images 1.normal 2.cataract 3.glaucoma 4.Retina Disease\n",
    "test_set = test_datagen.flow_from_directory('final_1/test', target_size = (150, 150), batch_size = 10, class_mode = 'categorical')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "45/45 [==============================] - 96s 2s/step - loss: 1.2875 - acc: 0.4867 - val_loss: 1.2560 - val_acc: 0.5040\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 1.2645 - acc: 0.5131 - val_loss: 1.2435 - val_acc: 0.5020\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 70s 2s/step - loss: 1.2867 - acc: 0.4824 - val_loss: 1.2800 - val_acc: 0.4860\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 1.2358 - acc: 0.5198 - val_loss: 1.2364 - val_acc: 0.5100\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 1.2034 - acc: 0.4936 - val_loss: 1.3183 - val_acc: 0.4920\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 1.2106 - acc: 0.5198 - val_loss: 1.2687 - val_acc: 0.4980\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 70s 2s/step - loss: 1.1492 - acc: 0.5442 - val_loss: 1.2770 - val_acc: 0.4680\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 1.1707 - acc: 0.5220 - val_loss: 1.2041 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 1.0855 - acc: 0.5731 - val_loss: 1.1527 - val_acc: 0.5260\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 1.1457 - acc: 0.5469 - val_loss: 1.1580 - val_acc: 0.5200\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 70s 2s/step - loss: 1.1292 - acc: 0.5291 - val_loss: 1.1285 - val_acc: 0.5080\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 70s 2s/step - loss: 1.0827 - acc: 0.5736 - val_loss: 1.0969 - val_acc: 0.5140\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 1.0466 - acc: 0.5754 - val_loss: 1.2520 - val_acc: 0.5120\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 1.0385 - acc: 0.5669 - val_loss: 1.1431 - val_acc: 0.5140\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.9646 - acc: 0.6243 - val_loss: 1.0587 - val_acc: 0.5480\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 1.0369 - acc: 0.5731 - val_loss: 1.1104 - val_acc: 0.5380\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.9514 - acc: 0.6398 - val_loss: 1.0657 - val_acc: 0.5400\n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.9637 - acc: 0.6158 - val_loss: 1.0101 - val_acc: 0.5700\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 1.0089 - acc: 0.6221 - val_loss: 1.0568 - val_acc: 0.5760\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 0.9827 - acc: 0.6403 - val_loss: 1.1098 - val_acc: 0.5280\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.9922 - acc: 0.6109 - val_loss: 1.0200 - val_acc: 0.5960\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.8914 - acc: 0.6532 - val_loss: 1.0157 - val_acc: 0.5880\n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.8792 - acc: 0.6843 - val_loss: 1.0506 - val_acc: 0.5320\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 0.9238 - acc: 0.6269 - val_loss: 0.9728 - val_acc: 0.6140\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 0.8797 - acc: 0.6425 - val_loss: 1.0102 - val_acc: 0.6140\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.9235 - acc: 0.6243 - val_loss: 1.0811 - val_acc: 0.5340\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.7906 - acc: 0.6888 - val_loss: 0.9850 - val_acc: 0.5740\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.9360 - acc: 0.6514 - val_loss: 0.9799 - val_acc: 0.5960\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 0.8381 - acc: 0.6799 - val_loss: 1.0338 - val_acc: 0.5560\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.8011 - acc: 0.6821 - val_loss: 0.9842 - val_acc: 0.6020\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.8455 - acc: 0.6710 - val_loss: 1.0123 - val_acc: 0.5700\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.8154 - acc: 0.6732 - val_loss: 1.0046 - val_acc: 0.5560\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 0.7542 - acc: 0.7132 - val_loss: 1.0142 - val_acc: 0.5760\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.7678 - acc: 0.6781 - val_loss: 1.0730 - val_acc: 0.5240\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.7975 - acc: 0.6936 - val_loss: 1.1048 - val_acc: 0.5660\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.8107 - acc: 0.7021 - val_loss: 0.9932 - val_acc: 0.5500\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.7135 - acc: 0.7065 - val_loss: 0.9775 - val_acc: 0.5720\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 0.7646 - acc: 0.6910 - val_loss: 1.0358 - val_acc: 0.4740\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.6635 - acc: 0.7421 - val_loss: 1.0865 - val_acc: 0.5320\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.7382 - acc: 0.7065 - val_loss: 1.0880 - val_acc: 0.5520\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.6690 - acc: 0.7221 - val_loss: 1.0938 - val_acc: 0.5180\n",
      "Epoch 42/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 0.6548 - acc: 0.7688 - val_loss: 1.0640 - val_acc: 0.5840\n",
      "Epoch 43/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.7016 - acc: 0.7199 - val_loss: 1.1784 - val_acc: 0.5360\n",
      "Epoch 44/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.6490 - acc: 0.7621 - val_loss: 1.2573 - val_acc: 0.4640\n",
      "Epoch 45/50\n",
      "45/45 [==============================] - 68s 2s/step - loss: 0.7256 - acc: 0.7159 - val_loss: 1.2662 - val_acc: 0.4900\n",
      "Epoch 46/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 0.7656 - acc: 0.7310 - val_loss: 0.9562 - val_acc: 0.5900\n",
      "Epoch 47/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 0.6513 - acc: 0.7600 - val_loss: 1.0983 - val_acc: 0.5660\n",
      "Epoch 48/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 0.6095 - acc: 0.7554 - val_loss: 1.0370 - val_acc: 0.5380\n",
      "Epoch 49/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 0.6114 - acc: 0.7559 - val_loss: 1.1582 - val_acc: 0.5580\n",
      "Epoch 50/50\n",
      "45/45 [==============================] - 69s 2s/step - loss: 0.5391 - acc: 0.7755 - val_loss: 1.0833 - val_acc: 0.5860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6078c9be80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model on the training and test images\n",
    "#samples per epoch determine number of images passing each epoch\n",
    "# nb_epoch specifies the number of times the network passes through the dataset\n",
    "# nb_val_samples determine the number of samples on which the model is validated\n",
    "eye_NN.fit_generator(training_set, samples_per_epoch = 450, nb_epoch = 50, validation_data = test_set, nb_val_samples = 50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T07:06:07.050386Z",
     "start_time": "2020-11-22T07:06:07.045067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user input image :\n"
     ]
    }
   ],
   "source": [
    "user_image = image.load_img('final_1/test/1_normal/NL_008.png', target_size = (150, 150)) # taking the user input for evaluation\n",
    " \n",
    "user_image = image.img_to_array(user_image)                                          # flattening the image into numy array\n",
    "\n",
    "user_image = np.expand_dims(user_image, axis = 0)                                    # adds a fake dimension because predict function expects batch of images\n",
    " \n",
    "output = eye_NN.predict_classes(user_image)                                      # calling the predict method\n",
    "\n",
    "print(\"The user input image :\")\n",
    "Image(filename='final_1/test/1_normal/NL_008.png',  width = 150, height = 80) # Loading image in output that the user wants to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T07:06:36.989513Z",
     "start_time": "2020-11-22T07:06:36.982723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class preditction is [0]\n",
      "Congratulations, you have a perfectly  normal eye\n"
     ]
    }
   ],
   "source": [
    "print(\"Class preditction is\", output)\n",
    "\n",
    "if output== 0:\n",
    "    prediction = 'normal eye'\n",
    "    print(\"Congratulations, you have a perfectly \",prediction)\n",
    "\n",
    "elif output == 1:\n",
    "    prediction = 'cataract'\n",
    "    print(\"It seems that you are suffering from \",prediction)    \n",
    "\n",
    "elif output == 2:\n",
    "    prediction = 'Glaucoma'\n",
    "    print(\"It seems that you are suffering from \",prediction)    \n",
    "     \n",
    "else:\n",
    "    prediction = 'Retina Disease'\n",
    "    print(\"It seems that you are suffering from  \",prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T07:07:01.284192Z",
     "start_time": "2020-11-22T07:07:01.273020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9248)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2367744   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 2,425,956\n",
      "Trainable params: 2,425,956\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# For printing a string summary of the network\n",
    "eye_NN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T07:07:39.065360Z",
     "start_time": "2020-11-22T07:07:39.060864Z"
    }
   },
   "outputs": [],
   "source": [
    "# For outputting Keras Graph\n",
    "%show_model eye_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
